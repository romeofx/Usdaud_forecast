{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941ff12d-236e-43b7-848a-1f74bf40a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   time     open     high      low    close  tick_volume  \\\n",
      "995 2025-06-30 13:18:00  3281.16  3282.02  3281.04  3281.42          164   \n",
      "996 2025-06-30 13:19:00  3281.41  3282.23  3281.28  3282.19          104   \n",
      "997 2025-06-30 13:20:00  3282.18  3282.46  3280.17  3280.80          161   \n",
      "998 2025-06-30 13:21:00  3280.80  3281.51  3279.84  3280.22          173   \n",
      "999 2025-06-30 13:22:00  3280.21  3280.31  3280.11  3280.16           34   \n",
      "\n",
      "     spread  real_volume  \n",
      "995      12            0  \n",
      "996      12            0  \n",
      "997      12            0  \n",
      "998      12            0  \n",
      "999      12            0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Connect to MetaTrader 5\n",
    "if not mt5.initialize():\n",
    "    print(\"MT5 Initialization failed:\", mt5.last_error())\n",
    "    quit()\n",
    "\n",
    "# Set symbol\n",
    "symbol = \"XAUUSD\"\n",
    "\n",
    "# Ensure symbol is available\n",
    "if not mt5.symbol_select(symbol, True):\n",
    "    print(f\"Failed to select {symbol}\")\n",
    "    mt5.shutdown()\n",
    "    quit()\n",
    "\n",
    "# Get last 1000 1-minute candles\n",
    "rates = mt5.copy_rates_from_pos(symbol, mt5.TIMEFRAME_M1, 0, 1000)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rates)\n",
    "df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "\n",
    "# Show last few rows\n",
    "print(df.tail())\n",
    "\n",
    "# Save for training\n",
    "df.to_csv(\"xauusd_data.csv\", index=False)\n",
    "\n",
    "# Disconnect\n",
    "mt5.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b88625-e008-473a-bf0d-ba0b5d254eab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdata\u001b[49m.type()\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b844f2c6-164a-480f-82f7-76687401891c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.1399\n",
      "Epoch 2/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0056\n",
      "Epoch 3/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0037\n",
      "Epoch 4/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0026\n",
      "Epoch 5/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0026\n",
      "Epoch 6/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0023\n",
      "Epoch 7/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0023\n",
      "Epoch 8/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0022\n",
      "Epoch 9/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0025\n",
      "Epoch 10/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0022\n",
      "Epoch 11/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0022\n",
      "Epoch 12/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0021\n",
      "Epoch 13/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0019\n",
      "Epoch 14/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0020\n",
      "Epoch 15/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0017\n",
      "Epoch 16/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0020\n",
      "Epoch 17/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0019\n",
      "Epoch 18/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0016\n",
      "Epoch 19/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0019\n",
      "Epoch 20/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016\n",
      "Epoch 21/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015\n",
      "Epoch 22/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0015\n",
      "Epoch 23/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015\n",
      "Epoch 24/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0015\n",
      "Epoch 25/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0017\n",
      "Epoch 26/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0017\n",
      "Epoch 27/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0017\n",
      "Epoch 28/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0015\n",
      "Epoch 29/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0013\n",
      "Epoch 30/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0016\n",
      "Epoch 31/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012\n",
      "Epoch 32/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0013\n",
      "Epoch 33/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0013\n",
      "Epoch 34/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0012\n",
      "Epoch 35/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0011\n",
      "Epoch 36/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011\n",
      "Epoch 37/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0014\n",
      "Epoch 38/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0015\n",
      "Epoch 39/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0011\n",
      "Epoch 40/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012\n",
      "Epoch 41/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0011\n",
      "Epoch 42/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011\n",
      "Epoch 43/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0011\n",
      "Epoch 44/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012\n",
      "Epoch 45/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0010\n",
      "Epoch 46/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011\n",
      "Epoch 47/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 9.8491e-04\n",
      "Epoch 48/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 9.9198e-04\n",
      "Epoch 49/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 8.8850e-04\n",
      "Epoch 50/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.8942e-04\n",
      "Epoch 51/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 8.5946e-04\n",
      "Epoch 52/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 8.4480e-04\n",
      "Epoch 53/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3960e-04\n",
      "Epoch 54/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 8.9850e-04\n",
      "Epoch 55/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.5036e-04\n",
      "Epoch 56/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.7696e-04\n",
      "Epoch 57/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 7.7335e-04\n",
      "Epoch 58/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 8.5629e-04\n",
      "Epoch 59/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.3721e-04\n",
      "Epoch 60/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.6923e-04\n",
      "Epoch 61/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 8.6900e-04\n",
      "Epoch 62/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.3470e-04\n",
      "Epoch 63/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.9120e-04\n",
      "Epoch 64/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.3912e-04\n",
      "Epoch 65/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.8494e-04\n",
      "Epoch 66/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 6.8154e-04\n",
      "Epoch 67/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.0689e-04\n",
      "Epoch 68/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 8.9304e-04\n",
      "Epoch 69/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.4144e-04\n",
      "Epoch 70/70\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 6.7184e-04\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "✅ Models trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"xauusd_data.csv\")\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Focus on 'close' prices only\n",
    "data = df['close'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize close prices\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create LSTM-compatible sequences\n",
    "def create_lstm_data(data, window=60):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(data)):\n",
    "        X.append(data[i-window:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_lstm_data(scaled_data)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Reshape for LSTM input: (samples, time_steps, features)\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    LSTM(50),\n",
    "    Dense(1)\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train LSTM\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=70, batch_size=32)\n",
    "\n",
    "# Save models directory\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# ✅ Save LSTM in native format\n",
    "lstm_model.save(\"models/lstm_model.keras\")\n",
    "\n",
    "# LSTM predictions to use in XGBoost\n",
    "lstm_preds_train = lstm_model.predict(X_train_lstm)\n",
    "X_train_xgb = np.hstack((X_train, lstm_preds_train))\n",
    "\n",
    "lstm_preds_test = lstm_model.predict(X_test_lstm)\n",
    "X_test_xgb = np.hstack((X_test, lstm_preds_test))\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100)\n",
    "xgb_model.fit(X_train_xgb, y_train)\n",
    "\n",
    "# Save XGBoost model and scaler\n",
    "xgb_model.save_model(\"models/xgboost_model.json\")\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "\n",
    "print(\"✅ Models trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1862877-afc6-4b3a-a131-e31e2b589ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load LSTM model (native format)\n",
    "lstm_model = load_model(\"models/lstm_model.keras\")  # ⬅️ No 'mse' error here\n",
    "\n",
    "# Load XGBoost model and scaler\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.load_model(\"models/xgboost_model.json\")\n",
    "scaler = joblib.load(\"models/scaler.pkl\")\n",
    "\n",
    "# Signal generator logic\n",
    "def generate_signal(predicted_price, current_price, threshold=0.002):\n",
    "    diff = (predicted_price - current_price) / current_price\n",
    "    if diff > threshold:\n",
    "        return \"BUY\"\n",
    "    elif diff < -threshold:\n",
    "        return \"SELL\"\n",
    "    else:\n",
    "        return \"HOLD\"\n",
    "\n",
    "# Forecast next price and give signal\n",
    "def forecast_next(close_prices: list):\n",
    "    if len(close_prices) < 60:\n",
    "        raise ValueError(\"Input must have at least 60 closing prices.\")\n",
    "\n",
    "    # Scale the latest 60 prices\n",
    "    recent_data = np.array(close_prices[-60:]).reshape(-1, 1)\n",
    "    scaled = scaler.transform(recent_data)\n",
    "\n",
    "    # Predict with LSTM\n",
    "    X_lstm = scaled.reshape(1, 60, 1)\n",
    "    lstm_pred = lstm_model.predict(X_lstm)\n",
    "\n",
    "    # Use LSTM output as extra feature for XGBoost\n",
    "    X_xgb = np.hstack((scaled.reshape(1, 60), lstm_pred))\n",
    "    xgb_pred = xgb_model.predict(X_xgb)\n",
    "\n",
    "    # Inverse transform to original price\n",
    "    predicted_scaled = xgb_pred[0]\n",
    "    predicted_price = scaler.inverse_transform([[predicted_scaled]])[0][0]\n",
    "\n",
    "    current_price = close_prices[-1]\n",
    "    signal = generate_signal(predicted_price, current_price)\n",
    "\n",
    "    return {\n",
    "        \"predicted_price\": round(predicted_price, 3),\n",
    "        \"current_price\": round(current_price, 3),\n",
    "        \"signal\": signal\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7348cd0-8512-41b8-a2a8-b1f1393b4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from app.forecast_logic import forecast_next\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class PriceInput(BaseModel):\n",
    "    close_prices: list\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"status\": \"XAUUSD AI API is running ✅\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(input: PriceInput):\n",
    "    result = forecast_next(input.close_prices)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a69805a9-f6f8-403d-826a-3393cde8e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.responses import HTMLResponse\n",
    "from app.forecast_logic import forecast_next\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "templates = Jinja2Templates(directory=\"app/templates\")\n",
    "\n",
    "class PriceInput(BaseModel):\n",
    "    close_prices: list\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "def read_root(request: Request):\n",
    "    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(input: PriceInput):\n",
    "    return forecast_next(input.close_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd540b-e2f0-4846-ae2b-569e2ec00fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
